# Name of your application. Used to uniquely configure containers.
service: ai_talk_coach

# Name of the container image.
image: zelusottomayor/ai_talk_coach

# Deploy to these servers.
servers:
  web:
    hosts:
      - 143.110.169.251
    # Apply resource limits based on imagesweep learnings to prevent runaway FFmpeg processes
    options:
      memory: "2g"        # Increased for audio processing workloads
      cpus: "1.0"         # Single core for web + background jobs

  # Uncomment for dedicated job processing (recommended for high-load production)
  # workers:
  #   hosts:
  #     - 143.110.169.251
  #   cmd: bin/jobs
  #   options:
  #     memory: "2g"      # Dedicated memory for audio processing
  #     cpus: "1.0"       # Single core for background jobs

# Enable SSL auto certification via Let's Encrypt and allow for multiple apps on a single web server.
# Remove this section when using multiple web servers and ensure you terminate SSL at your load balancer.
#
# Note: If using Cloudflare, set encryption mode in SSL/TLS setting to "Full" to enable CF-to-app encryption.
proxy:
  ssl: true
  host: aitalkcoach.com

# Credentials for your image host.
registry:
  # Using Docker Hub (default registry)
  username: zelusottomayor

  # Always use an access token rather than real password when possible.
  password:
    - KAMAL_REGISTRY_PASSWORD

# Inject ENV variables into containers (secrets come from .kamal/secrets).
env:
  secret:
    - RAILS_MASTER_KEY
    # External API keys for AI Talk Coach functionality
    - DEEPGRAM_API_KEY        # Speech-to-text transcription
    - OPENAI_API_KEY          # AI analysis and refinement
    - SENTRY_DSN              # Error monitoring
  clear:
    # Run the Solid Queue Supervisor inside the web server's Puma process to do jobs.
    # When you start using multiple servers, you should split out job processing to a dedicated machine.
    SOLID_QUEUE_IN_PUMA: true

    # Job processing configuration - tuned for audio processing workloads
    JOB_CONCURRENCY: 2           # Limit concurrent jobs to prevent resource exhaustion
    SOLID_QUEUE_POLLING_INTERVAL: 1  # Quick polling for responsiveness

    # Set number of cores available to the application on each server (default: 1).
    WEB_CONCURRENCY: 2           # Puma workers

    # Production optimizations
    RAILS_LOG_LEVEL: info
    RAILS_MAX_THREADS: 5
    DB_POOL_SIZE: 10

    # Memory management (based on imagesweep learnings)
    RUBY_GC_HEAP_GROWTH_FACTOR: 1.03   # Conservative GC tuning
    RUBY_GC_MALLOC_LIMIT: 40000000     # 40MB malloc limit

    # Timeouts for external services
    HTTP_TIMEOUT: 30             # HTTP client timeout for API calls
    JOB_TIMEOUT: 900             # 15 minute job timeout for long audio processing

# Aliases are triggered with "bin/kamal <alias>". You can overwrite arguments on invocation:
# "bin/kamal logs -r job" will tail logs from the first server in the job section.
aliases:
  console: app exec --interactive --reuse "bin/rails console"
  shell: app exec --interactive --reuse "bash"
  logs: app logs -f
  dbc: app exec --interactive --reuse "bin/rails dbconsole"

  # Monitoring and debugging aliases (based on imagesweep learnings)
  health: app exec "curl -f http://localhost/up || echo 'Health check failed'"
  htop: app exec --interactive --reuse "htop"
  cleanup: app exec "pkill -f ffmpeg || echo 'No ffmpeg processes to clean'"

# Use persistent storage volumes for SQLite databases and Active Storage files.
# Using mounted DigitalOcean volume for better persistence and performance.
volumes:
  - "/mnt/volume-lon1-01/aitalkcoach:/rails/storage"        # Active Storage files (audio uploads)
  - "/mnt/volume-lon1-01/aitalkcoach-logs:/rails/log"       # Application logs


# Bridge fingerprinted assets, like JS and CSS, between versions to avoid
# hitting 404 on in-flight requests. Combines all files from new and old
# version inside the asset_path.
asset_path: /rails/public/assets

# Configure the image builder.
builder:
  arch: amd64

  # # Build image via remote server (useful for faster amd64 builds on arm64 computers)
  # remote: ssh://docker@docker-builder-server
  #
  # # Pass arguments and secrets to the Docker build process
  # args:
  #   RUBY_VERSION: 3.3.0
  # secrets:
  #   - GITHUB_TOKEN
  #   - RAILS_MASTER_KEY

# Use a different ssh user than root
# ssh:
#   user: app

# Use accessory services (secrets come from .kamal/secrets).
# accessories:
#   db:
#     image: mysql:8.0
#     host: 192.168.0.2
#     # Change to 3306 to expose port to the world instead of just local network.
#     port: "127.0.0.1:3306:3306"
#     env:
#       clear:
#         MYSQL_ROOT_HOST: '%'
#       secret:
#         - MYSQL_ROOT_PASSWORD
#     files:
#       - config/mysql/production.cnf:/etc/mysql/my.cnf
#       - db/production.sql:/docker-entrypoint-initdb.d/setup.sql
#     directories:
#       - data:/var/lib/mysql
#   redis:
#     image: redis:7.0
#     host: 192.168.0.2
#     port: 6379
#     directories:
#       - data:/data
